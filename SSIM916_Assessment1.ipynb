{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cecfbd6d",
   "metadata": {},
   "source": [
    "# Comparison of Random Forest and XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59e0df-2663-4350-85e6-e7b3b00d3a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "!python -m pip install xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71c30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset\n",
    "df = pd.read_excel('Data/globalterrorismdb_0522dist.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d3add4",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "##### Look at the data structure and identify repeated entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09227c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "print(df.describe()) # describe the data to identify columns with missing data\n",
    "print(df.head()) # visualise the dataset\n",
    "print(df.columns.tolist) # get column names\n",
    "\n",
    "## repeated values\n",
    "print(df['eventid'].duplicated().sum()) # check for any repeated event ID numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64151ce1",
   "metadata": {},
   "source": [
    "##### Select rows to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8ccced",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select rows after 1997 as not all variables were measured before this\n",
    "df = df[df[\"iyear\"]>1997]\n",
    "\n",
    "## select rows that dont have NA value for nwound as that is the target variable\n",
    "df = df[~df[\"nwound\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23808486",
   "metadata": {},
   "source": [
    "##### Handle NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2997932b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventid</th>\n",
       "      <th>iyear</th>\n",
       "      <th>imonth</th>\n",
       "      <th>iday</th>\n",
       "      <th>extended</th>\n",
       "      <th>resolution</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>ransomamt</th>\n",
       "      <th>ransomamtus</th>\n",
       "      <th>ransompaid</th>\n",
       "      <th>ransompaidus</th>\n",
       "      <th>hostkidoutcome</th>\n",
       "      <th>nreleased</th>\n",
       "      <th>INT_LOG</th>\n",
       "      <th>INT_IDEO</th>\n",
       "      <th>INT_MISC</th>\n",
       "      <th>INT_ANY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.303430e+05</td>\n",
       "      <td>130343.000000</td>\n",
       "      <td>130343.000000</td>\n",
       "      <td>130343.000000</td>\n",
       "      <td>130343.000000</td>\n",
       "      <td>3384</td>\n",
       "      <td>130343.000000</td>\n",
       "      <td>130343.000000</td>\n",
       "      <td>129457.000000</td>\n",
       "      <td>129457.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>5.560000e+02</td>\n",
       "      <td>6.030000e+02</td>\n",
       "      <td>544.000000</td>\n",
       "      <td>8489.000000</td>\n",
       "      <td>8283.000000</td>\n",
       "      <td>130343.000000</td>\n",
       "      <td>130343.000000</td>\n",
       "      <td>130343.000000</td>\n",
       "      <td>130343.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.013285e+11</td>\n",
       "      <td>2013.218784</td>\n",
       "      <td>6.454140</td>\n",
       "      <td>15.599043</td>\n",
       "      <td>0.042051</td>\n",
       "      <td>2014-01-05 21:51:42.301713920</td>\n",
       "      <td>120.938424</td>\n",
       "      <td>7.914955</td>\n",
       "      <td>26.242281</td>\n",
       "      <td>50.910150</td>\n",
       "      <td>...</td>\n",
       "      <td>2.585992e+06</td>\n",
       "      <td>1.837380e+05</td>\n",
       "      <td>6.285185e+05</td>\n",
       "      <td>102.795956</td>\n",
       "      <td>4.127106</td>\n",
       "      <td>-15.346372</td>\n",
       "      <td>-4.947799</td>\n",
       "      <td>-4.849528</td>\n",
       "      <td>0.067307</td>\n",
       "      <td>-4.468364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.998010e+11</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1993-11-08 00:00:00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-43.532941</td>\n",
       "      <td>-158.081142</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.900000e+01</td>\n",
       "      <td>-9.900000e+01</td>\n",
       "      <td>-9.900000e+01</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.011060e+11</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012-01-29 06:00:00</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.024380</td>\n",
       "      <td>38.350204</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.900000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.900000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.014082e+11</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014-12-09 00:00:00</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>32.422925</td>\n",
       "      <td>44.921904</td>\n",
       "      <td>...</td>\n",
       "      <td>7.991325e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.017021e+11</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-04-30 00:00:00</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>34.359073</td>\n",
       "      <td>70.736484</td>\n",
       "      <td>...</td>\n",
       "      <td>2.143390e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.020123e+11</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-05-29 00:00:00</td>\n",
       "      <td>1004.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>74.633553</td>\n",
       "      <td>179.366667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000e+08</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>2.750000e+08</td>\n",
       "      <td>48000.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.897885e+08</td>\n",
       "      <td>4.898438</td>\n",
       "      <td>3.382279</td>\n",
       "      <td>8.800148</td>\n",
       "      <td>0.200705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.904161</td>\n",
       "      <td>2.402349</td>\n",
       "      <td>13.704486</td>\n",
       "      <td>38.021373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.562966e+07</td>\n",
       "      <td>1.340904e+06</td>\n",
       "      <td>1.129283e+07</td>\n",
       "      <td>2101.677559</td>\n",
       "      <td>1.854061</td>\n",
       "      <td>49.762500</td>\n",
       "      <td>4.513486</td>\n",
       "      <td>4.630881</td>\n",
       "      <td>0.332297</td>\n",
       "      <td>4.693287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            eventid          iyear         imonth           iday  \\\n",
       "count  1.303430e+05  130343.000000  130343.000000  130343.000000   \n",
       "mean   2.013285e+11    2013.218784       6.454140      15.599043   \n",
       "min    1.998010e+11    1998.000000       1.000000       0.000000   \n",
       "25%    2.011060e+11    2011.000000       4.000000       8.000000   \n",
       "50%    2.014082e+11    2014.000000       6.000000      15.000000   \n",
       "75%    2.017021e+11    2017.000000       9.000000      23.000000   \n",
       "max    2.020123e+11    2020.000000      12.000000      31.000000   \n",
       "std    4.897885e+08       4.898438       3.382279       8.800148   \n",
       "\n",
       "            extended                     resolution        country  \\\n",
       "count  130343.000000                           3384  130343.000000   \n",
       "mean        0.042051  2014-01-05 21:51:42.301713920     120.938424   \n",
       "min         0.000000            1993-11-08 00:00:00       4.000000   \n",
       "25%         0.000000            2012-01-29 06:00:00      92.000000   \n",
       "50%         0.000000            2014-12-09 00:00:00      95.000000   \n",
       "75%         0.000000            2017-04-30 00:00:00     160.000000   \n",
       "max         1.000000            2021-05-29 00:00:00    1004.000000   \n",
       "std         0.200705                            NaN      97.904161   \n",
       "\n",
       "              region       latitude      longitude  ...     ransomamt  \\\n",
       "count  130343.000000  129457.000000  129457.000000  ...  6.680000e+02   \n",
       "mean        7.914955      26.242281      50.910150  ...  2.585992e+06   \n",
       "min         1.000000     -43.532941    -158.081142  ... -9.900000e+01   \n",
       "25%         6.000000      15.024380      38.350204  ... -9.900000e+01   \n",
       "50%         8.000000      32.422925      44.921904  ...  7.991325e+03   \n",
       "75%        10.000000      34.359073      70.736484  ...  2.143390e+05   \n",
       "max        12.000000      74.633553     179.366667  ...  2.000000e+08   \n",
       "std         2.402349      13.704486      38.021373  ...  1.562966e+07   \n",
       "\n",
       "        ransomamtus    ransompaid  ransompaidus  hostkidoutcome    nreleased  \\\n",
       "count  5.560000e+02  6.030000e+02    544.000000     8489.000000  8283.000000   \n",
       "mean   1.837380e+05  6.285185e+05    102.795956        4.127106   -15.346372   \n",
       "min   -9.900000e+01 -9.900000e+01    -99.000000        1.000000  -100.000000   \n",
       "25%    0.000000e+00 -9.900000e+01      0.000000        2.000000     0.000000   \n",
       "50%    0.000000e+00  0.000000e+00      0.000000        4.000000     0.000000   \n",
       "75%    0.000000e+00  0.000000e+00      0.000000        6.000000     2.000000   \n",
       "max    2.000000e+07  2.750000e+08  48000.000000        7.000000  1201.000000   \n",
       "std    1.340904e+06  1.129283e+07   2101.677559        1.854061    49.762500   \n",
       "\n",
       "             INT_LOG       INT_IDEO       INT_MISC        INT_ANY  \n",
       "count  130343.000000  130343.000000  130343.000000  130343.000000  \n",
       "mean       -4.947799      -4.849528       0.067307      -4.468364  \n",
       "min        -9.000000      -9.000000      -9.000000      -9.000000  \n",
       "25%        -9.000000      -9.000000       0.000000      -9.000000  \n",
       "50%        -9.000000      -9.000000       0.000000      -9.000000  \n",
       "75%         0.000000       0.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "std         4.513486       4.630881       0.332297       4.693287  \n",
       "\n",
       "[8 rows x 78 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af174b",
   "metadata": {},
   "source": [
    "##### Identify relevant columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get non-NA counts for each column that will be selected for features\n",
    "sel_cols = df[[\"iyear\",\"imonth\",\"iday\",\"extended\",\"crit1\",\"crit2\",\"crit3\",\"multiple\",\n",
    "\"country\",\"region_txt\",\"vicinity\",\"attacktype1_txt\",\"success\",\"suicide\",\n",
    "\"weaptype1_txt\",\"weaptype2_txt\",\"targtype1_txt\",\"nperps\",\"nwound\",\"property\",\n",
    "\"nhostkid\"]]\n",
    "col_counts = sel_cols.count()\n",
    "na_counts = col_counts[col_counts < 130343] # 130343 is the number of entries in columns with no na values\n",
    "\n",
    "# print columns that are missing values, and how many entries they have\n",
    "for col, count in na_counts.items():\n",
    "    print(f\"{col} = {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e9ce1",
   "metadata": {},
   "source": [
    "##### Remove NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a8b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in NA values\n",
    "## weaptype2 - replace with none, as it is likely there was no additional weapon used,\n",
    "## leading to blank entries\n",
    "df[\"weaptype2_txt\"] = df[\"weaptype2_txt\"].fillna(\"None\")\n",
    "\n",
    "## nperps - 11972 out of 130343 entries were NA, replace with an average of the \n",
    "## existing values\n",
    "mean_nperps = df[\"nperps\"].mean()\n",
    "df[\"nperps\"] = df[\"nperps\"].fillna(mean_nperps)\n",
    "\n",
    "## nhostkid - assumed blank/NA entries are due to no hostage situation so NA is \n",
    "## replaced with 0\n",
    "df[\"nhostkid\"] = df[\"nhostkid\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b70fd",
   "metadata": {},
   "source": [
    "##### Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ce44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transformation\n",
    "##create dummy variables\n",
    "cols_to_encode = ['region_txt','attacktype1_txt','weaptype1_txt','weaptype2_txt','targtype1_txt'] \n",
    "prefixes = ['Region', 'AttackType', 'Weapon1', 'Weapon2', 'Target'] #new column names\n",
    "df = pd.get_dummies(df, columns=cols_to_encode, prefix=prefixes, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad40e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "##cleaning column names - removing spaces and symbols so they can be used as features\n",
    "df.columns = (df.columns\n",
    "    .str.replace(' & ', '_', regex=False)\n",
    "    .str.replace(' ', '_', regex=False)\n",
    "    .str.replace('/', '_', regex=False)\n",
    "    .str.replace('-', '_', regex=False)\n",
    "    .str.replace('(', '', regex=False)\n",
    "    .str.replace(')', '', regex=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e0242",
   "metadata": {},
   "source": [
    "## First test of algorithms\n",
    "### Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and confirm column names for feature selection\n",
    "# use ^ to find column names that begin with assigned names\n",
    "## Attack type\n",
    "df_attack = df.filter(regex='^AttackType')\n",
    "print(df_attack.columns.tolist())\n",
    "\n",
    "## Weapon 1\n",
    "df_w1 = df.filter(regex='^Weapon1')\n",
    "print(df_w1.columns.tolist())\n",
    "\n",
    "## Weapon 2\n",
    "df_w2 = df.filter(regex='^Weapon2')\n",
    "print(df_w2.columns.tolist())\n",
    "\n",
    "## Target\n",
    "df_targ = df.filter(regex='^Target')\n",
    "print(df_targ.columns.tolist())\n",
    "\n",
    "## Region\n",
    "df_reg = df.filter(regex='^Region')\n",
    "print(df_reg.columns.tolist())\n",
    "\n",
    "# rename column names that are too long\n",
    "df = df.rename(columns = {'Weapon1_Vehicle_not_to_include_vehicle_borne_explosives,_i.e.,_car_or_truck_bombs':'Weapon1_Vehicle',\n",
    "'Weapon2_Vehicle_not_to_include_vehicle_borne_explosives,_i.e.,_car_or_truck_bombs':'Weapon2_Vehicle'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2b9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "features = [\"iyear\",\"imonth\",\"iday\",\"extended\",\"crit1\",\"crit2\",\"crit3\",\n",
    "\"multiple\",\"country\",\"Region_North_America\",\"Region_Central_America_Caribbean\",\n",
    "\"Region_South_America\",\"Region_East_Asia\",\"Region_Southeast_Asia\",\"Region_South_Asia\",\n",
    "\"Region_Central_Asia\",\"Region_Western_Europe\",\"Region_Eastern_Europe\",\n",
    "\"Region_Middle_East_North_Africa\",\"Region_Sub_Saharan_Africa\",\n",
    "\"Region_Australasia_Oceania\",\"vicinity\",\"AttackType_Assassination\",\n",
    "\"AttackType_Hijacking\",\"AttackType_Hostage_Taking_Kidnapping\",\n",
    "\"AttackType_Hostage_Taking_Barricade_Incident\",\"AttackType_Bombing_Explosion\",\n",
    "\"AttackType_Armed_Assault\",\"AttackType_Unarmed_Assault\",\n",
    "\"AttackType_Facility_Infrastructure_Attack\",\"AttackType_Unknown\",\"success\",\"suicide\",\n",
    "\"Weapon1_Biological\",\"Weapon1_Chemical\",\"Weapon1_Radiological\",\"Weapon1_Firearms\",\n",
    "\"Weapon1_Explosives\",\"Weapon1_Fake_Weapons\",\"Weapon1_Incendiary\",\"Weapon1_Melee\",\"Weapon1_Sabotage_Equipment\",\"Weapon1_Other\",\"Weapon1_Unknown\",\n",
    "\"Weapon2_Biological\",\"Weapon2_Chemical\",\"Weapon2_Explosives\",\"Weapon2_Fake_Weapons\",\n",
    "\"Weapon2_Firearms\",\"Weapon2_Incendiary\",\"Weapon2_Melee\",\n",
    "\"Weapon2_Sabotage_Equipment\",\"Weapon2_Other\",\"Weapon2_Unknown\",\"Target_Business\",\n",
    "\"Target_Government_General\",\"Target_Police\",\"Target_Military\",\"Target_Abortion_Related\",\n",
    "\"Target_Airports_Aircraft\",\"Target_Government_Diplomatic\",\n",
    "\"Target_Educational_Institution\",\"Target_Food_or_Water_Supply\",\n",
    "\"Target_Journalists_Media\",\"Target_Maritime\",\"Target_NGO\",\"Target_Other\",\n",
    "\"Target_Private_Citizens_Property\",\"Target_Religious_Figures_Institutions\",\n",
    "\"Target_Telecommunication\",\"Target_Terrorists_Non_State_Militia\",\n",
    "\"Target_Tourists\",\"Target_Transportation\",\"Target_Unknown\",\"Target_Utilities\",\n",
    "\"Target_Violent_Political_Party\",\"nperps\",\"property\",\"nhostkid\"]\n",
    "target = 'nwound' # outcome variable\n",
    "\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de9fe89",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42) # 80/20 split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2709ec9d",
   "metadata": {},
   "source": [
    "### Random Forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor # want regression as nwound is numeric\n",
    "\n",
    "## set up the model\n",
    "rfr = RandomForestRegressor(n_estimators=100, criterion='squared_error', random_state=42)\n",
    "\n",
    "## fit the model\n",
    "rfr.fit(df_train[features], df_train[target])\n",
    "\n",
    "## Make predictions\n",
    "nwoundrf_pred = rfr.predict(df_test[features])\n",
    "\n",
    "## Calculate RMSE\n",
    "rmserf = np.sqrt(mean_squared_error(df_test[target], nwoundrf_pred))\n",
    "print(f'RMSE is {rmserf}')\n",
    "\n",
    "## Calculate R^2\n",
    "r2rf = r2_score(df_test[target], nwoundrf_pred)\n",
    "print(f'R-squared is {r2rf}')\n",
    "\n",
    "## Calculate MAE\n",
    "maerf = mean_absolute_error(df_test[target], nwoundrf_pred)\n",
    "print(f'MAE is {maerf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88197df9",
   "metadata": {},
   "source": [
    "### XGBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost regression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "## set up the model\n",
    "xgbr = XGBRegressor(n_estimators=100, objective='reg:squarederror', random_state=42)\n",
    "\n",
    "## Fit the model\n",
    "xgbr.fit(df_train[features], df_train[target])\n",
    "\n",
    "## Make predictions\n",
    "nwoundxg_pred = xgbr.predict(df_test[features])\n",
    "\n",
    "## Calculate RMSE\n",
    "rmsexg = np.sqrt(mean_squared_error(df_test[target], nwoundxg_pred))\n",
    "print(f'RMSE is {rmsexg}')\n",
    "\n",
    "## Calculate R^2\n",
    "r2xg = r2_score(df_test[target], nwoundxg_pred)\n",
    "print(f'R-squared is {r2xg}')\n",
    "\n",
    "## Calculate MAE\n",
    "maexg = mean_absolute_error(df_test[target], nwoundxg_pred)\n",
    "print(f'MAE is {maexg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8854a3e4",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "### Random Forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6f6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a random forest regression model\n",
    "cv_rfr = RandomForestRegressor(n_estimators=100, criterion='squared_error', random_state=42) # criterion for regression\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "## Define metrics\n",
    "rfr_metrics = ['neg_root_mean_squared_error', 'r2', 'neg_mean_absolute_error']\n",
    "\n",
    "## Calculate and print results\n",
    "print(\"5-Fold Cross-Validation Results:\")\n",
    "\n",
    "for metric in rfr_metrics:\n",
    "    cvrf_scores = cross_val_score(cv_rfr, df[features], df[target], cv=5, scoring=metric)\n",
    "    print(f\"\\n{metric.upper()}:\")\n",
    "    print(f\"  Individual fold scores: {cvrf_scores}\")\n",
    "    print(f\"  Mean: {cvrf_scores.mean():.4f} (+/- {cvrf_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe1241",
   "metadata": {},
   "source": [
    "### XGBoost regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72eae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBoost regression model\n",
    "cv_xgb = XGBRegressor(n_estimators=100, objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "## Define metrics\n",
    "xgb_metrics = ['neg_root_mean_squared_error', 'r2', 'neg_mean_absolute_error']\n",
    "\n",
    "## Calculate and print results\n",
    "print(\"5-Fold Cross-Validation Results:\")\n",
    "\n",
    "for metric in xgb_metrics:\n",
    "    cvxg_scores = cross_val_score(cv_xgb, df[features], df[target], cv=5, scoring=metric)\n",
    "    print(f\"\\n{metric.upper()}:\")\n",
    "    print(f\"  Individual fold scores: {cvxg_scores}\")\n",
    "    print(f\"  Mean: {cvxg_scores.mean():.4f} (+/- {cvxg_scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb554e7",
   "metadata": {},
   "source": [
    "### Select most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use random forest results\n",
    "# Get feature importances\n",
    "rfr_importances = rfr.feature_importances_\n",
    "\n",
    "# Sort by importance\n",
    "rfr_sorted_idx = np.argsort(rfr_importances)[::-1]\n",
    "rfr_sorted_features = [features[i] for i in rfr_sorted_idx]\n",
    "rfr_sorted_importances = rfr_importances[rfr_sorted_idx]\n",
    "\n",
    "# Select greater that 1/79\n",
    "for name, score in zip(rfr_sorted_features, rfr_sorted_importances):\n",
    "    if score > 0.0127:\n",
    "        print(f\"{name:<20}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb15c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select features from importances\n",
    "features = ['Weapon1_Biological','Weapon1_Chemical','Weapon1_Explosives',\n",
    "'Weapon1_Fake_Weapons','Weapon1_Firearms','Weapon1_Incendiary','Weapon1_Melee',\n",
    "'Weapon1_Other','Weapon1_Radiological','Weapon1_Sabotage_Equipment','Weapon1_Unknown',\n",
    "'Weapon1_Vehicle','Weapon2_Biological','Weapon2_Chemical','Weapon2_Explosives',\n",
    "'Weapon2_Fake_Weapons','Weapon2_Firearms','Weapon2_Incendiary','Weapon2_Melee',\n",
    "'Weapon2_None','Weapon2_Other','Weapon2_Sabotage_Equipment','Weapon2_Unknown',\n",
    "'Weapon2_Vehicle','Target_Abortion_Related','Target_Airports_Aircraft',\n",
    "'Target_Business','Target_Educational_Institution','Target_Food_or_Water_Supply', \n",
    "'Target_Government_Diplomatic','Target_Government_General','Target_Journalists_Media',\n",
    "'Target_Maritime','Target_Military','Target_NGO','Target_Other','Target_Police', \n",
    "'Target_Private_Citizens_Property','Target_Religious_Figures_Institutions',\n",
    "'Target_Telecommunication','Target_Terrorists_Non_State_Militia','Target_Tourists',\n",
    "'Target_Transportation','Target_Unknown','Target_Utilities',\n",
    "'Target_Violent_Political_Party','Region_Australasia_Oceania',\n",
    "'Region_Central_America_Caribbean','Region_Central_Asia','Region_East_Asia', \n",
    "'Region_Eastern_Europe','Region_Middle_East_North_Africa','Region_North_America',\n",
    "'Region_South_America','Region_South_Asia','Region_Southeast_Asia',\n",
    "'Region_Sub_Saharan_Africa','Region_Western_Europe','nhostkid','iday','imonth','iyear']\n",
    "\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4d989",
   "metadata": {},
   "source": [
    "### Run on single split\n",
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc21ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor # want regression as nwound is numeric\n",
    "\n",
    "## set up the model\n",
    "rfr = RandomForestRegressor(n_estimators=100, criterion='squared_error', random_state=42)\n",
    "\n",
    "## fit the model\n",
    "rfr.fit(df_train[features], df_train[target])\n",
    "\n",
    "## Make predictions\n",
    "nwoundrf_pred = rfr.predict(df_test[features])\n",
    "\n",
    "## Calculate RMSE\n",
    "rmserf = np.sqrt(mean_squared_error(df_test[target], nwoundrf_pred))\n",
    "print(f'RMSE is {rmserf}')\n",
    "\n",
    "## Calculate R^2\n",
    "r2rf = r2_score(df_test[target], nwoundrf_pred)\n",
    "print(f'R-squared is {r2rf}')\n",
    "\n",
    "## Calculate MAE\n",
    "maerf = mean_absolute_error(df_test[target], nwoundrf_pred)\n",
    "print(f'MAE is {maerf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd72d7",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost regression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "## set up the model\n",
    "xgbr = XGBRegressor(n_estimators=100, objective='reg:squarederror', random_state=42)\n",
    "\n",
    "## Fit the model\n",
    "xgbr.fit(df_train[features], df_train[target])\n",
    "\n",
    "## Make predictions\n",
    "nwoundxg_pred = xgbr.predict(df_test[features])\n",
    "\n",
    "## Calculate RMSE\n",
    "rmsexg = np.sqrt(mean_squared_error(df_test[target], nwoundxg_pred))\n",
    "print(f'RMSE is {rmsexg}')\n",
    "\n",
    "## Calculate R^2\n",
    "r2xg = r2_score(df_test[target], nwoundxg_pred)\n",
    "print(f'R-squared is {r2xg}')\n",
    "\n",
    "## Calculate MAE\n",
    "maexg = mean_absolute_error(df_test[target], nwoundxg_pred)\n",
    "print(f'MAE is {maexg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff4470",
   "metadata": {},
   "source": [
    "## Reduce number of features manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd9c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features Region and AttackType as they are likely to be the first bits of\n",
    "# information available in the case of an attack\n",
    "features = [\"Region_North_America\",\"Region_Central_America_Caribbean\",\n",
    "\"Region_South_America\",\"Region_East_Asia\",\"Region_Southeast_Asia\",\"Region_South_Asia\",\n",
    "\"Region_Central_Asia\",\"Region_Western_Europe\",\"Region_Eastern_Europe\",\n",
    "\"Region_Middle_East_North_Africa\",\"Region_Sub_Saharan_Africa\",\n",
    "\"Region_Australasia_Oceania\",\"AttackType_Assassination\",\n",
    "\"AttackType_Hijacking\",\"AttackType_Hostage_Taking_Kidnapping\",\n",
    "\"AttackType_Hostage_Taking_Barricade_Incident\",\"AttackType_Bombing_Explosion\",\n",
    "\"AttackType_Armed_Assault\",\"AttackType_Unarmed_Assault\",\n",
    "\"AttackType_Facility_Infrastructure_Attack\",\"AttackType_Unknown\"]\n",
    "target = 'nwound'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888cea2",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda26c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor # want regression as nwound is numeric\n",
    "\n",
    "## set up the model\n",
    "rfr = RandomForestRegressor(n_estimators=100, criterion='squared_error', random_state=42)\n",
    "\n",
    "## fit the model\n",
    "rfr.fit(df_train[features], df_train[target])\n",
    "\n",
    "## Make predictions\n",
    "nwoundrf_pred = rfr.predict(df_test[features])\n",
    "\n",
    "## Calculate RMSE\n",
    "rmserf = np.sqrt(mean_squared_error(df_test[target], nwoundrf_pred))\n",
    "print(f'RMSE is {rmserf}')\n",
    "\n",
    "## Calculate R^2\n",
    "r2rf = r2_score(df_test[target], nwoundrf_pred)\n",
    "print(f'R-squared is {r2rf}')\n",
    "\n",
    "## Calculate MAE\n",
    "maerf = mean_absolute_error(df_test[target], nwoundrf_pred)\n",
    "print(f'MAE is {maerf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d4043",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost regression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "## set up the model\n",
    "xgbr = XGBRegressor(n_estimators=100, objective='reg:squarederror', random_state=42)\n",
    "\n",
    "## Fit the model\n",
    "xgbr.fit(df_train[features], df_train[target])\n",
    "\n",
    "## Make predictions\n",
    "nwoundxg_pred = xgbr.predict(df_test[features])\n",
    "\n",
    "## Calculate RMSE\n",
    "rmsexg = np.sqrt(mean_squared_error(df_test[target], nwoundxg_pred))\n",
    "print(f'RMSE is {rmsexg}')\n",
    "\n",
    "## Calculate R^2\n",
    "r2xg = r2_score(df_test[target], nwoundxg_pred)\n",
    "print(f'R-squared is {r2xg}')\n",
    "\n",
    "## Calculate MAE\n",
    "maexg = mean_absolute_error(df_test[target], nwoundxg_pred)\n",
    "print(f'MAE is {maexg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a28230",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define parameter list, balancing with computational efficiency\n",
    "rf_param_distributions = {\n",
    "    'n_estimators': [100],          # fixed\n",
    "    'max_depth': [5, 8],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4]\n",
    "}\n",
    "\n",
    "# Define random forest model\n",
    "hp_rfr = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=hp_rfr,\n",
    "    param_grid=rf_param_distributions,\n",
    "    cv=2,                      # 2-fold CV\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on training data\n",
    "rf_grid_search.fit(df_train[features], df_train[target])\n",
    "\n",
    "# Print best parameters and CV score\n",
    "print(\"GRID SEARCH RESULTS\")\n",
    "print(f\"Best parameters: {rf_grid_search.best_params_}\")\n",
    "print(f\"Best CV R2 score: {rf_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "rf_y_pred = rf_grid_search.predict(df_test[features])\n",
    "\n",
    "# Calculate scores \n",
    "rmse = np.sqrt(mean_squared_error(df_test[target], rf_y_pred))\n",
    "mae = mean_absolute_error(df_test[target], rf_y_pred)\n",
    "r2 = r2_score(df_test[target], rf_y_pred)\n",
    "\n",
    "# Print scores\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R2: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb75ca",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecba9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for XGBoost\n",
    "xgb_param_distributions = {\n",
    "    'n_estimators': [100],          # fixed for speed\n",
    "    'max_depth': [5, 8],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Define XGBoost model\n",
    "hp_xgb = XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "xgb_grid_search = GridSearchCV(\n",
    "    estimator=hp_xgb,\n",
    "    param_grid=xgb_param_distributions,\n",
    "    cv=2,                      # 2-fold CV for large dataset\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on training data\n",
    "xgb_grid_search.fit(df_train[features], df_train[target])\n",
    "\n",
    "# Print best parameters and CV score\n",
    "print(\"XGBOOST GRID SEARCH RESULTS\")\n",
    "print(f\"Best parameters: {xgb_grid_search.best_params_}\")\n",
    "print(f\"Best CV R2 score: {xgb_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "xgb_y_pred = xgb_grid_search.predict(df_test[features])\n",
    "\n",
    "# Calculate scores\n",
    "rmse = np.sqrt(mean_squared_error(df_test[target], xgb_y_pred))\n",
    "mae = mean_absolute_error(df_test[target], xgb_y_pred)\n",
    "r2 = r2_score(df_test[target], xgb_y_pred)\n",
    "\n",
    "# Print scores\n",
    "print(\"\\nTest Set Performance (XGBoost):\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R2: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
